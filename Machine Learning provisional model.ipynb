{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef212bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for numerical computing\n",
    "import numpy as np\n",
    "\n",
    "# for dataframes\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83c5a290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge  # Linear Regression + L2 regularization\n",
    "from sklearn.linear_model import Lasso  # Linear Regression + L1 regularization\n",
    "from sklearn.svm import SVR # Support Vector Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d8d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f07e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3536864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import xgboost (this is Gradient Boost ML Model)\n",
    "import os\n",
    "mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-7.2.0-posix-seh-rt_v5-rev0\\\\mingw64\\\\bin'\n",
    "os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance  # to plot feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4635f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation, enter in our csv file, or json if we go that route\n",
    "\n",
    "df = pd.read_csv(\"__________.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f166a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b441b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test splits (update target variable to our specific model, such as lat/long or radius, or price?)\n",
    "# Create separate object for target variable\n",
    "y = df.tx_price\n",
    "# Create separate object for input features\n",
    "X = df.drop('tx_price', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a46a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split X and y into train and test sets: 80-20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cce7d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm we have the right number of observations in each subset.\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55ffe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data standardization\n",
    "\n",
    "train_mean = X_train.mean()\n",
    "train_std = X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9283b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the train data set\n",
    "\n",
    "X_train = (X_train - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0be44ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for mean and std dev.\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d136abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Note: We use train_mean and train_std_dev to standardize test data set\n",
    "X_test = (X_test - train_mean) / train_std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b62ecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for mean and std dev. - not exactly 0 and 1\n",
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b0d18f",
   "metadata": {},
   "source": [
    "## Model 1 - Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f893a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict Train results\n",
    "y_train_pred = np.ones(y_train.shape[0])*y_train.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb6d009",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict Test results\n",
    "y_pred = np.ones(y_test.shape[0])*y_train.mean()\n",
    "km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ce6814",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Results for Baseline Model:\")\n",
    "print(\"*******************************\")\n",
    "print(\"Root mean squared error: \", sqrt(mse(y_train.values, y_train_pred)))\n",
    "print(\"R-squared: \", r2_score(y_train.values, y_train_pred))\n",
    "print(\"Mean Absolute Error: \", mae(y_train.values, y_train_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549ffe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results for Baseline Model:\")\n",
    "print(\"*******************************\")\n",
    "print(\"Root mean squared error: \", sqrt(mse(y_test, y_pred)))\n",
    "print(\"R-squared: \", r2_score(y_test, y_pred))\n",
    "print(\"Mean Absolute Error: \", mae(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644f0791",
   "metadata": {},
   "source": [
    "## Model 2 - Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0999f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reference for random search on random forest\n",
    "## https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "tuned_params = {'n_estimators': [100, 200, 300, 400, 500], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}\n",
    "model = RandomizedSearchCV(RandomForestRegressor(), tuned_params, n_iter=20, scoring = 'neg_mean_absolute_error', cv=5, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "## This takes around 15 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ba5442",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c7e370",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict Train results\n",
    "y_train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daec6494",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict Test results\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9c3c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Results for Random Forest Regression:\")\n",
    "print(\"*******************************\")\n",
    "print(\"Root mean squared error: \", sqrt(mse(y_train.values, y_train_pred)))\n",
    "print(\"R-squared: \", r2_score(y_train.values, y_train_pred))\n",
    "print(\"Mean Absolute Error: \", mae(y_train.values, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db47d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Results for Random Forest Regression:\")\n",
    "print(\"*******************************\")\n",
    "print(\"Root mean squared error: \", sqrt(mse(y_test, y_pred)))\n",
    "print(\"R-squared: \", r2_score(y_test, y_pred))\n",
    "print(\"Mean Absolute Error: \", mae(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba660309",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# RFR Feature Importance, do we need this section?\n",
    "## Building the model again with the best hyperparameters\n",
    "model = RandomForestRegressor(n_estimators=200, min_samples_split=10, min_samples_leaf=2)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2df5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not sure if we need this importance section?\n",
    "indices = np.argsort(-model.feature_importances_)\n",
    "print(\"The features in order of importance are:\")\n",
    "print(50*'-')\n",
    "for feature in X.columns[indices]:\n",
    "    print(feature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0d1378",
   "metadata": {},
   "source": [
    "## Model 3 - XGBoost Regression (Gradient Boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ed4fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reference for random search on xgboost\n",
    "## https://gist.github.com/wrwr/3f6b66bf4ee01bf48be965f60d14454d\n",
    "tuned_params = {'max_depth': [1, 2, 3, 4, 5], 'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [100, 200, 300, 400, 500], 'reg_lambda': [0.001, 0.1, 1.0, 10.0, 100.0]}\n",
    "model = RandomizedSearchCV(XGBRegressor(), tuned_params, n_iter=20, scoring = 'neg_mean_absolute_error', cv=5, n_jobs=-1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de54655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42589eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict Train results\n",
    "y_train_pred = model.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bb6dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict Test results\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20653b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Train Results for XGBoost Regression:\")\n",
    "print(\"*******************************\")\n",
    "print(\"Root mean squared error: \", sqrt(mse(y_train.values, y_train_pred)))\n",
    "print(\"R-squared: \", rs(y_train.values, y_train_pred))\n",
    "print(\"Mean Absolute Error: \", mae(y_train.values, y_train_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb221937",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Test Results for XGBoost Regression:\")\n",
    "print(\"*******************************\")\n",
    "print(\"Root mean squared error: \", sqrt(mse(y_test, y_pred)))\n",
    "print(\"R-squared: \", r2_score(y_test, y_pred))\n",
    "print(\"Mean Absolute Error: \", mae(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ff8ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance, again, not sure if we'll need this part...\n",
    "\n",
    "## Building the model again with the best hyperparameters\n",
    "model = XGBRegressor(max_depth=2,learning_rate=0.05,n_estimators=400, reg_lambda=0.001)\n",
    "model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e734a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to include figsize parameter\n",
    "## Reference: https://stackoverflow.com/questions/40081888/xgboost-plot-importance-figure-size\n",
    "def my_plot_importance(booster, figsize, **kwargs): \n",
    "    from matplotlib import pyplot as plt\n",
    "    from xgboost import plot_importance\n",
    "    fig, ax = plt.subplots(1,1,figsize=figsize)\n",
    "    return plot_importance(booster=booster, ax=ax, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fda0a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not sure if we want a feature importance horizontal bar plot\n",
    "my_plot_importance(model, (10,10))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
